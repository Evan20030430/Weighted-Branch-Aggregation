{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6m9_LNizT7s",
        "outputId": "d18d274d-f076-4ce4-bb7b-f0d198bdfad1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as func\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files\n",
        "import time\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5voKoTH-zUV3"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/VIP/Custom ML Model/\" #Path of train/test data\n",
        "train_path = path + \"Train/\"\n",
        "test_path = path + \"Test/\"\n",
        "\n",
        "train_data = os.listdir(train_path + \"Train Data\")\n",
        "train_label = os.listdir(train_path + \"Train Label\")\n",
        "test_data = os.listdir(test_path + \"Test Data\")\n",
        "test_label = os.listdir(test_path + \"Test Label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1y4pG0VzWP3"
      },
      "outputs": [],
      "source": [
        "class dataset(Dataset):\n",
        "  def __init__(self,test=False,transf=transforms.ToTensor()):\n",
        "    super().__init__()\n",
        "    self.test=test\n",
        "    self.trans = transf\n",
        "    if test:\n",
        "      self.data = test_data\n",
        "      self.labels = test_label\n",
        "    else:\n",
        "      self.data = train_data\n",
        "      self.labels = train_label\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    data_name = self.data[idx]\n",
        "    if self.test:\n",
        "      data = Image.open(test_path + \"Test Data/\" + data_name)\n",
        "      label = Image.open(test_path + \"Test Label/\" + data_name) # data name same as label name\n",
        "      data = data.resize((320, 320)) # Resize image to pass into model\n",
        "      label = func.rgb_to_grayscale(label, num_output_channels=1) # convert label to grayscale\n",
        "      label = label.resize((320,320))\n",
        "      return self.trans(data), self.trans(label), data_name\n",
        "    else:\n",
        "      data = Image.open(train_path + \"Train Data/\" + data_name)\n",
        "      label = Image.open(train_path + \"Train Label/\" + data_name) # data name same as label name\n",
        "      data = data.resize((320, 320))\n",
        "      label = func.rgb_to_grayscale(label, num_output_channels=1)\n",
        "      label = label.resize((320,320))\n",
        "      return self.trans(data), self.trans(label), data_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xd5eIXwizYUC"
      },
      "outputs": [],
      "source": [
        "def train_model(model, data_loader, loss, optimizer, epochs):\n",
        "  device=torch.device('cuda:0') # Use GPU to run\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "  loss_list=[]\n",
        "  b_list=[]\n",
        "  for epoch in range(epochs):\n",
        "    print(\"Epoch: \", (epoch + 1))\n",
        "    model.train()\n",
        "    for data, label, _ in tqdm(train_data_load):\n",
        "      data=data.to(device)\n",
        "      label = label.to(device)\n",
        "      output, _, _ = model(data)\n",
        "      batch_loss = loss(output, label)\n",
        "      optimizer.zero_grad()\n",
        "      batch_loss.backward()\n",
        "      optimizer.step()\n",
        "      b_list.append(batch_loss.cpu().detach().numpy())\n",
        "    loss_list.append(sum(b_list)/len(b_list))\n",
        "    print(\"Loss: \", sum(b_list)/len(b_list)) # Prints value of loss\n",
        "  return loss_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9XAGMxIzZj_"
      },
      "outputs": [],
      "source": [
        "class model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Branch 1: (larger stride/pool size/filter size) (General Feature)\n",
        "    self.b1_conv1 = nn.Sequential(\n",
        "                      nn.Conv2d(3, 64, kernel_size=3, stride=3),\n",
        "                      nn.LeakyReLU(),\n",
        "                      nn.AvgPool2d(kernel_size=3, stride=3),\n",
        "                      nn.Dropout2d(),\n",
        "                      nn.BatchNorm2d(64),\n",
        "                      nn.Upsample(size=128)                      \n",
        "                    )\n",
        "\n",
        "    self.b1_conv2 = nn.Sequential(\n",
        "                      nn.Conv2d(64, 256, kernel_size=3, stride=3),\n",
        "                      nn.LeakyReLU(),\n",
        "                      nn.AvgPool2d(kernel_size=3, stride=3),\n",
        "                      nn.BatchNorm2d(256)\n",
        "                    )\n",
        "\n",
        "    self.b1_resize = nn.Sequential(\n",
        "                        nn.ConvTranspose2d(256, 64, kernel_size=3, padding=(2,2)),\n",
        "                        nn.Upsample(size=64),\n",
        "                        nn.ConvTranspose2d(64, 1, kernel_size=3, padding=(2,2)),\n",
        "                        nn.Upsample(size=320)\n",
        "                     )\n",
        "\n",
        "    # Branch 2: local, smaller convolution kernels, or even 1x1 convolutions\n",
        "    self.b2_conv1 = nn.Sequential(\n",
        "                      nn.Conv2d(3, 128, kernel_size=2, stride=1),\n",
        "                      nn.LeakyReLU(),\n",
        "                      nn.AvgPool2d(kernel_size=2, stride=1),\n",
        "                      nn.BatchNorm2d(128)\n",
        "                    )\n",
        "\n",
        "    self.b2_conv2 = nn.Sequential(\n",
        "                      nn.Conv2d(128, 512, kernel_size=2, stride=2, padding=(2,2)),\n",
        "                      nn.LeakyReLU(),\n",
        "                      nn.AvgPool2d(kernel_size=2, stride=1),\n",
        "                      nn.BatchNorm2d(512)\n",
        "                    )\n",
        "\n",
        "    self.b2_resize = nn.Sequential(\n",
        "                      nn.ConvTranspose2d(512, 128, kernel_size=3, stride=3, padding=(3,3)),\n",
        "                      nn.ConvTranspose2d(128, 1, kernel_size=2, stride=2, padding=(2,2)), # only 1 feature channel --> grey scale\n",
        "                      nn.Upsample(320)\n",
        "                    )\n",
        "\n",
        "    # Final smoothen layer\n",
        "    self.fin_conv = nn.Sequential(\n",
        "                      nn.Conv2d(1, 1, kernel_size=2, stride=1, padding=1),\n",
        "                      nn.ConvTranspose2d(1, 1, kernel_size=4, stride=1, padding=(2,2)), \n",
        "                      nn.BatchNorm2d(1) \n",
        "                    )\n",
        "\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x):\n",
        "    # Branch 1\n",
        "    x1 = self.b1_conv1(x)\n",
        "    x1 = self.b1_conv2(x1)\n",
        "    x1 = self.b1_resize(x1)\n",
        "\n",
        "    # Branch 2\n",
        "    # Crop image (1/6 from top)\n",
        "    height = x.shape[2]\n",
        "    width = x.shape[3]\n",
        "    x2 = x[:,:,height//6:,:] # [8, 3, 267, 320]\n",
        "\n",
        "    x2 = self.b2_conv1(x)\n",
        "    x2 = self.b2_conv2(x2)\n",
        "\n",
        "    # fill cropped part with 0\n",
        "    fill_tensor = torch.zeros((x2.shape[0], x2.shape[1], (x2.shape[3]-x2.shape[2]), x2.shape[3]))\n",
        "    device=torch.device('cuda:0')\n",
        "    fill_tensor = fill_tensor.to(device) # convert tensor from cpu to gpu\n",
        "    x2 = torch.cat((fill_tensor, x2), 2) # concatenate top with 0\n",
        "\n",
        "    x2 = self.b2_resize(x2)\n",
        "\n",
        "    # Crop x1 and x2 into top, middle, bottom\n",
        "    x1_top = x1[:,:,:80,:] # 0 ~ 79 (top 1/4)\n",
        "    x1_mid = x1[:,:,80:160,:] # middle 1/4\n",
        "    x1_bot = x1[:,:,160:,:] # bottom 1/2\n",
        "\n",
        "    x2_top = x2[:,:,:80,:] # 0 ~ 79 (top 1/4)\n",
        "    x2_mid = x2[:,:,80:160,:] # middle 1/4\n",
        "    x2_bot = x2[:,:,160:,:] # bottom 1/2\n",
        "\n",
        "    # Apply weights to each branch and add them up\n",
        "    x_top = 0.7 * x1_top + 0.3 * x2_top # global feature heavy (7:3)\n",
        "    x_mid = 0.4 * x1_mid + 0.6 * x2_mid # 4:6\n",
        "    x_bot = 0.3 * x1_bot + 0.7 * x2_bot # local feature heavy (3:7)\n",
        "\n",
        "    # Concatenate top, mid, and bottom\n",
        "    x = torch.cat((x_top, x_mid, x_bot), 2)\n",
        "\n",
        "    # Smoothen convolutional layer\n",
        "    x = self.fin_conv(x)\n",
        "\n",
        "    return x, x1, x2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2FMu1cqzyoN"
      },
      "outputs": [],
      "source": [
        "# predict all images in test folder\n",
        "path = \"/content/drive/MyDrive/VIP/Custom ML Model/\" #Path of train/test data\n",
        "# train_path = path + \"Train/\"\n",
        "test_img_path = path + \"Test/Test Data/\"\n",
        "result_path = \"result/\"\n",
        "\n",
        "model.eval()\n",
        "test_data_obj=dataset(test=True)\n",
        "test_data_loader=DataLoader(test_data_obj, batch_size=8, shuffle=False)\n",
        "\n",
        "for data, _, img_name in test_data_loader:\n",
        "  device=torch.device('cuda:0')\n",
        "  data=data.to(device)\n",
        "  predictions, _, _ = model(data)\n",
        "\n",
        "  for i in range(len(predictions)):\n",
        "    pred = predictions[i].permute(1,2,0).cpu().detach().numpy()\n",
        "\n",
        "    thresh_1 = 0.5\n",
        "    plt.figure()\n",
        "    thresh_1_pred = pred\n",
        "    thresh_1_pred[thresh_1_pred < thresh_1] = 0 # post-processing\n",
        "    thresh_1_pred[thresh_1_pred > (thresh_1)] = 1 # post-processing\n",
        "    plt.imshow(thresh_1_pred, cmap='gray')\n",
        "    plt.tick_params(left = False, right = False , labelleft = False , labelbottom = False, bottom = False)\n",
        "    plt.savefig(result_path + \"mask_\" + img_name[i])\n",
        "\n",
        "    test_img=data[i].permute(1,2,0).cpu().detach().numpy()\n",
        "    plt.imshow(test_img, alpha = 0.6)\n",
        "    plt.tick_params(left = False, right = False , labelleft = False , labelbottom = False, bottom = False)\n",
        "    plt.savefig(result_path + \"result_\" + img_name[i])\n",
        "\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!zip -r /content/result.zip /content/result\n",
        "files.download(\"/content/result.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
